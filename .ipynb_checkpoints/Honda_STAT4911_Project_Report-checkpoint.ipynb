{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0ad0692",
   "metadata": {},
   "source": [
    "# STAT4911 Honda Capstone Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f8e31",
   "metadata": {},
   "source": [
    "### By Manasa Subramanian, Naveen Elliott, Jiajun Chen, and Andrew Coblentz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0f62a",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "## 1) Introduction\n",
    "## 2) Data Preprocessing\n",
    "## 3) Exploratory Data Analysis\n",
    "## 4) Building the Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d2d575",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1501ae",
   "metadata": {},
   "source": [
    "For this project, our group was tasked with identify improvement in supplier finance metrics, more specifically, to find leading indicators for financial instability. Ultimately, our goal was to identify key drivers and characteristics within the supplier base that may cause issues, so that Honda could proactively manage those issues. We took several multi-level approaches to this given task, but settled on using previous data to predict the current financial health rating of any given supplier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1f4e1f",
   "metadata": {},
   "source": [
    "## Provided Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c23f930",
   "metadata": {},
   "source": [
    "Our group was provided with detailed quarterly financial health data for all of the suppliers from RapidRatings, a company that Honda uses to provide a financial health rating on their suppliers by using publicly available financial health data. Furthermore, we were given detailed financial information for auto suppliers of Honda that contained many of the factors that are involved in RapidRatings financial health rating, including the financial health rating itself. Each row in this dataset also represented reporting by a supplier at a given time.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e846168",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7135be35",
   "metadata": {},
   "source": [
    "Before building models and conducting exploratory data analysis, we needed to first conduct some data preprocessing. First, we import all the data set we are going to use including the currency conversion datasets, which were obtained by manually going through each combination of currency and year. We will convert this to USD in 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d133d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fhr_data       = pd.read_csv(\"Cleaned_Data/cleaned_fhr_data.csv\")\n",
    "extract_data   = pd.read_csv(\"Cleaned_Data/cleaned_detailed_supplier.csv\")\n",
    "conversion     = pd.read_csv(\"conversions.csv\")          # currency â†’ USD rates\n",
    "inflation      = pd.read_csv(\"Cleaned_Data/inflation rate.csv\")       # yearly inflation\n",
    "\n",
    "# Rename key for joining\n",
    "extract_data = extract_data.rename(\n",
    "    columns={\"Vlookup Supplier #\": \"Supplier Number\"}\n",
    ")\n",
    "\n",
    "# Static supplier attributes (unique per supplier)\n",
    "fhr_static = (\n",
    "    fhr_data[[\"Supplier Number\", \"Data Source\",\n",
    "              \"Group\", \"Group Classification\", \"Parent ID\"]]\n",
    "    .drop_duplicates(\"Supplier Number\")\n",
    ")\n",
    "\n",
    "# merge the two datasets that we use for prediction\n",
    "merged_data = extract_data.merge(\n",
    "    fhr_static, on=\"Supplier Number\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5481a1d3",
   "metadata": {},
   "source": [
    "We now want to merge the currency conversion data into the merged financial health data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39e2e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first merge the conversion_data and inflation_data by year\n",
    "money = (\n",
    "    conversion\n",
    "    .merge(inflation, left_on=\"eqyYear\", right_on=\"Year\", how=\"left\")\n",
    ")\n",
    "\n",
    "merged_data = merged_data.merge(\n",
    "    money, on=[\"eqyYear\", \"currency\"], how=\"left\"\n",
    ")\n",
    "\n",
    "# check the inflation rate for usd and convert other currencies to USD\n",
    "is_usd = merged_data[\"currency\"].eq(\"USD\")\n",
    "infl_map = inflation.set_index(\"Year\")[\"Inflation Rate (%)\"]\n",
    "\n",
    "merged_data.loc[is_usd, \"Inflation Rate (%)\"] \\\n",
    "    = merged_data.loc[is_usd, \"eqyYear\"].map(infl_map)\n",
    "merged_data.loc[is_usd, \"X.Other.Currency.to.USD\"] = 1.0\n",
    "\n",
    "merged_data.drop(columns={'Unnamed: 0', 'Data Source', 'Group Classification', 'count', 'USD to Other Currency'}, inplace=True)\n",
    "\n",
    "merged_data = merged_data.sort_values(by=['Supplier Number','financialDate'])\n",
    "\n",
    "merged_data['financialDate'] = pd.to_datetime(merged_data['financialDate'])\n",
    "\n",
    "# getting previous FHR and CHS\n",
    "merged_data['prev_FHR'] = merged_data.groupby('Supplier Number')['FHR'].shift(1)\n",
    "merged_data['prev_CHS'] = merged_data.groupby('Supplier Number')['CHS'].shift(1)\n",
    "merged_data['prev_financialDate'] = merged_data.groupby('Supplier Number')['financialDate'].shift(1)\n",
    "\n",
    "merged_data['prev_financialDate'] = pd.to_datetime(merged_data['prev_financialDate'])\n",
    "merged_data['diff_days'] = (merged_data['financialDate'] - merged_data['prev_financialDate']).dt.days\n",
    "\n",
    "#merged_data.to_csv(\"final_merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d9f1d",
   "metadata": {},
   "source": [
    "Now we will convert the desired columns to USD in 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "220e8114",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Other Currency to USD'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Other Currency to USD'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26228/3605288364.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# convert based on inflation factor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m scale_factor = (\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mfinal_merged\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Other Currency to USD\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;33m*\u001b[0m \u001b[0mfinal_merged\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"inf_factor\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Other Currency to USD'"
     ]
    }
   ],
   "source": [
    "final_merged = pd.read_csv(\"final_merged.csv\")          # output of earlier steps\n",
    "infl_factors = pd.read_csv(\"inflation_factor.csv\")      # 2025 / year factors\n",
    "# merge the financial health file with final inflation factor\n",
    "final_merged = final_merged.merge(\n",
    "    infl_factors, left_on=\"eqyYear\", right_on=\"eqy_year\", how=\"left\"\n",
    ")\n",
    "\n",
    "# get non-monetary columns so we exclude them when we convert later\n",
    "non_monetary = {\n",
    "    \"Supplier Number\", \"eqyYear\", \"currency\",\n",
    "    \"X.Other.Currency.to.USD\", \"inf_factor\",\n",
    "    \"Inflation Rate\", \"FHR\", \"CHS\"\n",
    "}\n",
    "\n",
    "numeric_cols = (\n",
    "    final_merged\n",
    "    .select_dtypes(include=\"number\")\n",
    "    .columns.difference(non_monetary)\n",
    ")\n",
    "\n",
    "# convert based on inflation factor.\n",
    "scale_factor = (\n",
    "    final_merged[\"X.Other.Currency.to.USD\"]\n",
    "    * final_merged[\"inf_factor\"]\n",
    ")\n",
    "\n",
    "final_merged.loc[:, numeric_cols] = (\n",
    "    final_merged[numeric_cols].mul(scale_factor, axis=0)\n",
    ")\n",
    "\n",
    "#final_merged.to_csv(\"final_merged_updated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e028d",
   "metadata": {},
   "source": [
    "Now that the data is properly formatted, we will look back at previous data and keep the current FHR (dependent variable). This will make it very easy for us to model on this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9556da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "merged = pd.read_csv('final_merged_updated.csv')\n",
    "\n",
    "merged.drop(columns={'Unnamed: 0'}, inplace=True)\n",
    "\n",
    "merged['financialDate'] = pd.to_datetime(merged['financialDate'])\n",
    "\n",
    "merged = merged.sort_values(by=['Supplier.Number','financialDate'])\n",
    "\n",
    "# For each column in the DataFrame, create a new column with the immediate previous entry (grouped by Supplier.Number)\n",
    "for col in merged.columns:\n",
    "    new_col = 'prev_' + col\n",
    "    merged[new_col] = merged.groupby('Supplier.Number')[col].shift(1)\n",
    "\n",
    "\n",
    "# Remove rows where there's no previous Supplier.Number (i.e. first row per supplier)\n",
    "merged = merged.loc[merged['prev_Supplier.Number'].notna()]\n",
    "\n",
    "# Convert previous financialDate column to datetime and calculate difference in days\n",
    "merged['prev_financialDate'] = pd.to_datetime(merged['prev_financialDate'])\n",
    "merged['diff_days'] = (merged['financialDate'] - merged['prev_financialDate']).dt.days\n",
    "\n",
    "# Calculate the difference in FHR\n",
    "merged['diff_FHR'] = merged['FHR'] - merged['prev_FHR']\n",
    "\n",
    "# Create a list of columns that start with 'prev_'\n",
    "prev_cols = [col for col in merged.columns if col.startswith('prev_')]\n",
    "\n",
    "# Add 'diff_days' and 'FHR' to that list\n",
    "cols_to_keep = prev_cols + ['diff_days', 'FHR']\n",
    "\n",
    "# Filter the DataFrame to keep only those columns\n",
    "merged = merged[cols_to_keep]\n",
    "\n",
    "\n",
    "merged.fillna(0, inplace=True)\n",
    "\n",
    "merged.drop(columns={'prev_Supplier.Number', 'prev_Inflation.Rate....', 'prev_Parent.ID', \n",
    "                     'prev_id', 'prev_RRID', 'prev_Group', 'prev_period'}, inplace=True)\n",
    "\n",
    "# save as CSV to use with modeling in the GitHub\n",
    "#merged.to_csv('final_previous_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4780cb61",
   "metadata": {},
   "source": [
    "To run a model to predict previous FHR, we needed to use our preprocessed dataset but groupby the supplier and shift it back to the previous time period. So each row in the new dataframe would consist of all of our features, including the previous FHR, and the current FHR (our y value). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43baee08",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6673f4",
   "metadata": {},
   "source": [
    "## Creating a Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0aac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "merged = pd.read_csv('final_merged_updated.csv')\n",
    "\n",
    "num_cols = merged[['abnormalItems', 'bankCashBalances', 'CHS', 'companyTaxExpense', 'debitOwnedWithinOneYear', \n",
    "                   'earningsBeforeInterestAndTax', 'eqyYear', 'FHR', 'financialAssets', 'fixedAssets', 'interestExpense', \n",
    "                  'netFundingCashFlow', 'netInvestingCashFlow', 'netProfitAfterTax', 'salesRevenue', 'termLoans', \n",
    "                  'totalAssets', 'totalCurrentAssets', 'totalCurrentLiabilities', 'totalLiabilities', 'totalShareholderEquity']]\n",
    "corr_matrix = num_cols.corr()\n",
    "\n",
    "# creating correlation matrix\n",
    "sns.heatmap(corr_matrix, annot=False,cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4bd8f5",
   "metadata": {},
   "source": [
    "The linear correlation between monetary variables are extremely high, which suggests that monetary variables have a high multicollinearity and we should take caution with using too many as direct predictors for a linear model. Therefore, to help mitigate this risk of overfitting, we can non-linear models (eg. random forest or xGBoost) or linear models with feature selection (lasso and ridge regression). Interestingly enough, three of the variables with low multicollinearity (FHR, CHS, and eqyYear) ended up being the best predictors of future FHR in our lasso model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb0cd5",
   "metadata": {},
   "source": [
    "## Creating Currency EDA Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd8ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from highlight_text import fig_text\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "merged = pd.read_csv('final_previous_merged.csv')\n",
    "\n",
    "# Define the order of currencies (alphabetical order, or change as needed)\n",
    "order = sorted(merged['prev_currency'].unique())\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = ['#009b3a', '#D80621', '#DA291C', '#EE1C25', '#003399', '#CE1124', '#FF671F', \n",
    "          '#BC002D', '#CD2E3A', '#006341', '#BA0C2F', '#FE0000', '#B31942']\n",
    "\n",
    "# Create the boxplot with the defined order\n",
    "sns.boxplot(data=merged, x='prev_currency', y='FHR', ax=ax, order=order, palette=colors)\n",
    "\n",
    "# Set axis labels\n",
    "plt.xlabel(\"\", fontsize=15)\n",
    "plt.ylabel(\"FHR\", fontsize=15)\n",
    "\n",
    "# Set up a custom font for the title and add a custom title\n",
    "font_path = 'C:/Users/Owner/Downloads/SoccermaticsForPython-master/SoccermaticsForPython-master/RussoOne-Regular.ttf'\n",
    "title = FontProperties(fname=font_path)\n",
    "fig_text(\n",
    "    x=0.5, y=0.91, \n",
    "    s=\"How Does Currency Relate to FHR\",\n",
    "    va=\"bottom\", ha=\"center\",\n",
    "    color=\"black\", fontproperties=title, fontsize=18\n",
    ")\n",
    "\n",
    "# Get the x-axis tick positions; these correspond to the positions for 'order'\n",
    "tick_positions = ax.get_xticks()\n",
    "\n",
    "# Remove the default tick labels so we can add custom ones\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "# Folder where flag images are stored (make sure filenames match, e.g., \"USD.png\")\n",
    "flag_folder = \"Flags\"\n",
    "\n",
    "# Loop over the currencies and add the corresponding flag and currency code\n",
    "for pos, cat in zip(tick_positions, order):\n",
    "    # Construct the file path for the flag image\n",
    "    flag_path = os.path.join(flag_folder, f\"{cat}.png\")\n",
    "    try:\n",
    "        # Load the image and create an OffsetImage object (adjust zoom as needed)\n",
    "        img = plt.imread(flag_path)\n",
    "        im = OffsetImage(img, zoom=0.1)\n",
    "        # Place the image at the appropriate x position and a fixed y position\n",
    "        ab = AnnotationBbox(im, (pos, -0.05),\n",
    "                            xycoords=('data', 'axes fraction'),\n",
    "                            frameon=False,\n",
    "                            box_alignment=(0.5, 1))\n",
    "        ax.add_artist(ab)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Flag image for {cat} not found at {flag_path}.\")\n",
    "    # Add the currency code text below the flag image using the x-axis transform\n",
    "    ax.text(pos, -0.14, cat, transform=ax.get_xaxis_transform(), \n",
    "            ha='center', va='top', fontsize=10)\n",
    "\n",
    "# Optionally, remove the top and right spines for a cleaner look\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Compute the count of rows for each currency\n",
    "group_counts = merged.groupby('prev_currency').size()\n",
    "\n",
    "# For each currency, determine a y-axis position slightly above its boxplot\n",
    "for pos, cat in zip(tick_positions, order):\n",
    "    count = group_counts.get(cat, 0)\n",
    "    # Determine a y position: here we use the maximum FHR value for that currency and add an offset.\n",
    "    max_val = merged[merged['prev_currency'] == cat]['FHR'].max()\n",
    "    # The offset can be defined as a percentage of the max value (here, 5%)\n",
    "    offset = 0.025 * max_val\n",
    "    ax.text(pos, max_val + offset, f\"N = {count}\", ha='center', va='bottom', \n",
    "            fontsize=10, color='#222222')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764ed7e7",
   "metadata": {},
   "source": [
    "From this plot, we can determine that country does indeed have an effect on FHR. However, it's effect can be hard to determine because of the limited sample size in certain areas, like Norway or Brazil. Despite this, there are still some notable trends such as Japanese and Canadian supplirs tending to have higher FHR ratings than Taiwanese and Amercian suppliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4019b7b",
   "metadata": {},
   "source": [
    "# Building the Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4596be9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from highlight_text import fig_text, ax_text\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "\n",
    "\n",
    "# loading font for plots\n",
    "font_path = \"C:/Users/Owner/Downloads/SoccermaticsForPython-master/SoccermaticsForPython-master/AccidentalPresidency.ttf\"\n",
    "belanosima = FontProperties(fname=font_path)\n",
    "\n",
    "merged = pd.read_csv('final_previous_merged.csv')\n",
    "\n",
    "plotting = merged.copy()\n",
    "\n",
    "plotting.dropna(subset=['prev_FHR'], inplace=True)\n",
    "\n",
    "plotting = plotting.sort_values(by='diff_days', ascending=True)\n",
    "\n",
    "\n",
    "mean_prev_fhr = merged['prev_FHR'].mean()\n",
    "mean_prev_chs = merged['prev_CHS'].mean()\n",
    "mean_diff_days = merged['diff_days'].mean()\n",
    "\n",
    "merged['prev_FHR'] = merged['prev_FHR'].fillna(mean_prev_fhr)\n",
    "merged['prev_CHS'] = merged['prev_CHS'].fillna(mean_prev_chs)\n",
    "merged['diff_days'] = merged['diff_days'].fillna(mean_diff_days)\n",
    "\n",
    "\n",
    "merged['diff_days_category'] = np.where(merged['diff_days'] > 365, 1, 0)\n",
    "\n",
    "above_1000 = len(merged.loc[merged['diff_days_category'] == 1])\n",
    "\n",
    "below_1000 = len(merged.loc[merged['diff_days_category'] == 0])\n",
    "\n",
    "merged_box = merged[['FHR', 'prev_FHR', 'diff_days_category']]\n",
    "\n",
    "# Create the scatterplot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "# Draw the regression line without scatter points\n",
    "sns.regplot(\n",
    "    x=\"prev_FHR\", \n",
    "    y=\"FHR\", \n",
    "    data=plotting, \n",
    "    scatter=False, \n",
    "    line_kws={'color': 'black'}\n",
    ")\n",
    "\n",
    "# Overlay the scatter plot with color mapping based on diff_days\n",
    "sc = ax.scatter(\n",
    "    plotting['prev_FHR'], \n",
    "    plotting['FHR'], \n",
    "    c=plotting['diff_days'], \n",
    "    cmap='coolwarm', \n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "# Add labels, title, and grid\n",
    "plt.xlabel(\"Previous FHR\", fontsize=18)\n",
    "plt.ylabel(\"FHR\", fontsize=18)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "fig_text(\n",
    "    x = 0.5, y = .92, \n",
    "    s = \"Previous FHR vs Current FHR\",  # Use <> around the text to be styled\n",
    "    va = \"bottom\", ha = \"center\",\n",
    "    color = \"black\", fontproperties = belanosima, weight = \"bold\", size=30\n",
    ")\n",
    "\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.set_label(\"Difference in Days\", fontsize=15)\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "df_reg = plotting.dropna(subset=['prev_FHR'])\n",
    "\n",
    "# Define the feature (previous FHR) and target (current FHR)\n",
    "X = df_reg[['prev_FHR']]\n",
    "y = df_reg['FHR']\n",
    "\n",
    "# Optional: split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R-Squared', r2)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f97e75",
   "metadata": {},
   "source": [
    "To start, we created a baseline model to predict the current FHR by solely using the previous FHR. For measuring the strength of our model we used the root mean squared error (RMSE) and r^2. The RMSE states how far off our models that predict FHR typically are from the actual FHR. R^2 is a statistic that measures the percentage of variability in FHR captured by our model. These metrics tell us that our baseline model does a good job of predicting current FHR by just using previous FHR. Our goal for the rest of the project is to beat this model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
